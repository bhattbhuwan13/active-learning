{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning : Using trained model to identify unlabelled images that are hard to classify and thus need to be labelled by human\n",
    "\n",
    "In this notebook, we will use the trained model to identify images which has the low probability score for the most probable class and save it to [weights and biases dashboard](https://wandb.ai/bhattbhuwan13/active-learning/runs/34g8uy09?workspace=user-bhattbhuwan13) so that those images can later be labelled by humans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose(\n",
    "    [\n",
    "     transforms.Resize(32), # The dataset loaded from the disk isn't 32 X 32 so we need to introduce\n",
    "#         transformations to make them 32 X 32\n",
    "     transforms.CenterCrop(32),\n",
    "     transforms.ToTensor(),\n",
    "#      transforms.Normalize((0.0, 0.0, 0.0), (255.0, 255.0, 255.0)),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "testset = ImageFolder(root='./test/', transform=test_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model\n",
    "\n",
    "We will use the same model from the previous notebook and then load the saved weights from the local drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "EPOCHS = 10\n",
    "DEVICE = 'cpu' # We will make predictions on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=3, \n",
    "                              out_channels=20, \n",
    "                              kernel_size=3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(20, 10, 3)\n",
    "#         self.fc1 = nn.Linear(10 * 3 * 3, 80)\n",
    "        self.fc1 = nn.Linear(360, 80)\n",
    "        self.fc2 = nn.Linear(80, 40)\n",
    "        self.fc3 = nn.Linear(40, n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x) # Should have passed this output to softmax layers before returning\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up weights and biases for logging images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: bhattbhuwan13 (use `wandb login --relogin` to force relogin)\n",
      "wandb: wandb version 0.12.4 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.30<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">expert-field-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/bhattbhuwan13/active-learning\" target=\"_blank\">https://wandb.ai/bhattbhuwan13/active-learning</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/bhattbhuwan13/active-learning/runs/34g8uy09\" target=\"_blank\">https://wandb.ai/bhattbhuwan13/active-learning/runs/34g8uy09</a><br/>\n",
       "                Run data is saved locally in <code>/home/ubuntu/active learning/wandb/run-20211010_155542-34g8uy09</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(34g8uy09)</h1><iframe src=\"https://wandb.ai/bhattbhuwan13/active-learning/runs/34g8uy09\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7efc1680f250>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import wandb\n",
    "\n",
    "# 1. Start a new run\n",
    "wandb.init(project='active-learning', entity='bhattbhuwan13')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for converting the normalized array back to normal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array2img(arr, \n",
    "              mean=[0.5, 0.5, 0.5], \n",
    "              std=[0.5, 0.5, 0.5]):\n",
    "\n",
    "    arr = arr.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array(mean)\n",
    "    std = np.array(std)\n",
    "    arr = std * arr + mean\n",
    "    arr = np.clip(arr, 0, 1)\n",
    "    arr = arr * 255\n",
    "    arr = arr.astype(int)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = './saved_model/active.pth'\n",
    "\n",
    "model = CNN(NUM_CLASSES)\n",
    "model.load_state_dict(torch.load(PATH, map_location=DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and save difficult images to weights and biases\n",
    "\n",
    "The code below uses the model to make predictions on unlabelled data and log difficult images(images for which the probability score of the most probable class is less than 0.5) to the weights and biases server. For each batch of predictions:\n",
    "\n",
    "- The model spits out probability of each sample belonging to one of 10 classes\n",
    "- If the highest probability score is less than 0.5, the sample is considered as difficult example and save to the weights and biases server\n",
    "\n",
    "**Note: For convinience, the code below runs for only one iteration(batch). However, upon removing the break statement, it will run for the entire set of unlabelled images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.to(DEVICE)\n",
    "        model = model.to(DEVICE)\n",
    "\n",
    "        predicted_values = model(images)\n",
    "        max_prob = torch.max(predicted_values.data, 1).values\n",
    "        max_prob = torch.where(max_prob<0.5) \n",
    "        difficult_images = images[max_prob] # filters out all\n",
    "        # those images for which the model has less confidence\n",
    "       \n",
    "        difficult_images_converted = [array2img(array) for array in difficult_images]\n",
    "        wandb.log({'images': [wandb.Image(image) for image in difficult_images_converted]})\n",
    "#         wandb.log({\"difficult examples\": difficult_images})\n",
    "#         to_log = [wandb.Image(image) for image in difficult_images_converted]\n",
    "#         table= wandb.Table(data=to_log, columns=['image'])\n",
    "#         wandb.log({\"cifar10_images\": table})\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p37)",
   "language": "python",
   "name": "conda_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
